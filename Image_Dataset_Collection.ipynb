{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiDsiM0xHwgf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import time\n",
        "\n",
        "# Define 20 search categories\n",
        "categories = [\n",
        "    \"Dogs\", \"Cats\", \"Cars\", \"Bikes\", \"Chairs\", \"Phones\", \"Mountains\", \"Laptops\", \"Bridges\", \"Birds\",\n",
        "    \"Trains\", \"Planets\", \"Monuments\", \"Flowers\", \"Street Food\", \"Waterfalls\", \"Ancient Temples\",\n",
        "    \"Futuristic Cities\", \"Wildlife\", \"Space Exploration\"\n",
        "]\n",
        "\n",
        "# Output directories\n",
        "output_folder = \"downloaded_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# CSV file to store metadata\n",
        "csv_file = open(\"image_metadata.csv\", \"w\", newline=\"\", encoding=\"utf-8\")\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow([\"Category\", \"Image URL\", \"Filename\", \"Resolution\"])\n",
        "\n",
        "# Set headers to mimic a real browser\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "def get_bing_image_urls(category, max_images=50):\n",
        "    \"\"\"Fetches actual image URLs from Bing Image Search.\"\"\"\n",
        "    search_url = f\"https://www.bing.com/images/search?q={category}&form=HDRSC2\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, headers=headers)\n",
        "        response.raise_for_status()  # Ensure request was successful\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ö†Ô∏è Error fetching search results for {category}: {e}\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    img_urls = []\n",
        "\n",
        "    # Extract image URLs from the search results\n",
        "    for img_tag in soup.find_all(\"a\", {\"class\": \"iusc\"}, limit=max_images):\n",
        "        try:\n",
        "            m_data = eval(img_tag[\"m\"])  # Extract image metadata (JSON-like structure)\n",
        "            img_url = m_data.get(\"murl\")  # Get the direct image URL\n",
        "\n",
        "            if img_url and img_url.startswith(\"http\"):\n",
        "                img_urls.append(img_url)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error parsing image data: {e}\")\n",
        "\n",
        "    return img_urls\n",
        "\n",
        "def download_images(category):\n",
        "    \"\"\"Downloads images using working Bing image URLs.\"\"\"\n",
        "    category_folder = os.path.join(output_folder, category)\n",
        "    os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "    img_urls = get_bing_image_urls(category, max_images=50)\n",
        "\n",
        "    for count, img_url in enumerate(img_urls):\n",
        "        try:\n",
        "            img_response = requests.get(img_url, headers=headers, stream=True)\n",
        "\n",
        "            # Validate image response\n",
        "            if \"image\" not in img_response.headers.get(\"Content-Type\", \"\"):\n",
        "                print(f\"‚ö†Ô∏è Skipping non-image file: {img_url}\")\n",
        "                continue\n",
        "\n",
        "            # Verify image integrity using Pillow\n",
        "            img = Image.open(BytesIO(img_response.content))\n",
        "            img.verify()\n",
        "\n",
        "            # Save the image\n",
        "            filename = f\"{category}_{count+1}.jpg\"\n",
        "            filepath = os.path.join(category_folder, filename)\n",
        "\n",
        "            with open(filepath, \"wb\") as f:\n",
        "                f.write(img_response.content)\n",
        "\n",
        "            # Get image resolution\n",
        "            img = Image.open(filepath)\n",
        "            resolution = f\"{img.width}x{img.height}\"\n",
        "\n",
        "            # Save metadata\n",
        "            csv_writer.writerow([category, img_url, filename, resolution])\n",
        "            print(f\"‚úÖ Downloaded {filename} ({resolution})\")\n",
        "\n",
        "            time.sleep(1)  # Prevent getting blocked by Bing\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error downloading {img_url}: {e}\")\n",
        "\n",
        "# Run image scraping\n",
        "for category in categories:\n",
        "    print(f\"üîç Searching images for {category}...\")\n",
        "    download_images(category)\n",
        "\n",
        "# Close CSV file\n",
        "csv_file.close()\n",
        "print(\"‚úÖ Image scraping complete!\")\n"
      ]
    }
  ]
}